"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RAG Semantic Quality Test
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PURPOSE:
    Validate the semantic understanding quality of the RAG system.
    This is THE CRITICAL TEST that validates whether rich conceptual descriptions
    enable proper semantic disambiguation between broad (domain-level) and 
    specific (transaction-level) intent.

TESTS INCLUDED:
    Test 3: Semantic Similarity (Broad vs Specific)
            Component: Embedding model + Rich descriptions
            Validates: Broadâ†’Groups, Specificâ†’Subcategories semantic mapping
            
            Part A: 10 BROAD terms â†’ should match category GROUPS
            Part B: 10 SPECIFIC terms â†’ should match SUBCATEGORIES

KEY INSIGHT:
    This test validates the CORE INNOVATION of using rich conceptual descriptions
    to enable semantic understanding rather than keyword matching:
    
    - "medicine" (broad/abstract) â†’ Healthcare & Medical GROUP
    - "dentist" (specific/concrete) â†’ Dental SUBCATEGORY
    
    Without proper descriptions, both would match the same way.

SUCCESS CRITERIA:
    - Part A (Broad â†’ Groups): â‰¥70% accuracy
    - Part B (Specific â†’ Subcategories): â‰¥90% accuracy  
    - Overall: â‰¥80% accuracy

USAGE:
    from tests.test_rag_semantic_quality import run_semantic_quality_test
    results = run_semantic_quality_test()
    
    # Or run directly
    from tests.test_rag_semantic_quality import test_semantic_similarity_broad_vs_specific
    test_semantic_similarity_broad_vs_specific()

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from typing import Dict, Any

# Import RAG components
from rag.trn_category_rag import query_categories


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HELPER FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_test_header(test_number: int, test_name: str, component: str, purpose: str):
    """Print formatted test header."""
    print("\n" + "=" * 80)
    print(f"TEST {test_number}: {test_name}")
    print("=" * 80)
    print(f"ğŸ“¦ COMPONENT: {component}")
    print(f"ğŸ¯ PURPOSE:   {purpose}")
    print("â”€" * 80)


def print_component_step(step_description: str):
    """Print component step being executed."""
    print(f"\nğŸ”§ {step_description}")


def print_result(status: bool, description: str, details: str = ""):
    """Print formatted result."""
    icon = "âœ…" if status else "âŒ"
    status_text = "PASS" if status else "FAIL"
    print(f"{icon} {status_text} | {description}")
    if details:
        print(f"         {details}")


def print_test_summary(test_number: int, passed: int, total: int):
    """Print test summary."""
    percentage = (passed / total * 100) if total > 0 else 0
    print("\n" + "â”€" * 80)
    print(f"ğŸ“Š TEST {test_number} SUMMARY")
    print("â”€" * 80)
    print(f"Total Checks:   {total}")
    print(f"âœ… Passed:      {passed}")
    print(f"âŒ Failed:      {total - passed}")
    print(f"Success Rate:   {percentage:.1f}%")
    print("â”€" * 80)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST 3: SEMANTIC SIMILARITY (BROAD VS SPECIFIC)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_semantic_similarity_broad_vs_specific(similarity_distance_threshold: float = 0.6) -> Dict[str, Any]:
    """
    Test 3: Semantic Similarity (Broad vs Specific)
    
    COMPONENT TESTED:
        multilingual-e5-base embedding model + Rich conceptual descriptions
        - Group descriptions (abstract, domain-level language)
        - Subcategory descriptions (concrete, transaction-level language)
    
    PURPOSE:
        Verify that the RAG system understands semantic INTENT and correctly
        distinguishes between:
        - BROAD queries (domain-level) â†’ should match GROUPS
        - SPECIFIC queries (transaction-level) â†’ should match SUBCATEGORIES
        
        This tests semantic understanding, NOT keyword matching.
    
    PARAMETERS:
        similarity_distance_threshold (float): Distance threshold for filtering (default: 0.6)
    
    WHAT THIS VALIDATES:
        âœ“ Rich conceptual descriptions enable semantic disambiguation
        âœ“ Embedding model captures intent differences (broad vs specific)
        âœ“ Groups have stronger semantic signal for abstract terms
        âœ“ Subcategories have stronger semantic signal for concrete terms
    
    WHY THIS MATTERS:
        This is THE CRITICAL TEST that proves rich descriptions work.
        
        Example of what we're testing:
        - "medicine" (broad) â†’ Should match Healthcare GROUP (CG300)
        - "dentist" (specific) â†’ Should match Dental SUBCATEGORY (C304)
        
        Without proper descriptions, both might match the same category.
        This test validates that semantic understanding disambiguates them.
    
    TEST DATA:
        Part A: 10 BROAD terms (e.g., "medicine", "food shopping", "eating out")
                â†’ Should match category GROUPS (abstract, domain-level)
        
        Part B: 10 SPECIFIC terms (e.g., "dentist", "coffee shop", "fuel")
                â†’ Should match SUBCATEGORIES (concrete, transaction-level)
    
    SUCCESS CRITERIA:
        - Part A (Broad â†’ Groups): â‰¥70% accuracy
        - Part B (Specific â†’ Subcategories): â‰¥90% accuracy
        - Overall: â‰¥80% accuracy
    """
    print_test_header(
        3,
        "Semantic Similarity (Broad vs Specific)",
        "Embedding Model + Rich Descriptions",
        "Verify semantic understanding distinguishes broad (domain) from specific (transaction) intent"
    )
    
    # PRINT CHOSEN THRESHOLD
    print(f"ğŸ¯ Using similarity_distance_threshold: {similarity_distance_threshold}")
    print("â”€" * 80)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART A: BROAD TERMS â†’ CATEGORY GROUPS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    broad_tests = [
        ("medicine", "CG300", "Healthcare & Medical"),
        ("food shopping", "CG10000", "Groceries"),
        ("eating out", "CG800", "Dining"),
        ("commute", "CG100", "Transportation"),
        ("home expenses", "CG1400", "Home & Garden"),
        ("kids activities", "CG1600", "Childcare & Kids"),
        ("working out", "CG1700", "Fitness & Sports"),
        ("protection coverage", "CG1000", "Insurance"),
        ("learning", "CG900", "Education"),
        ("charity work", "CG1200", "Charity & Donations"),
    ]
    
    print("\n" + "â”€" * 80)
    print("PART A: BROAD TERMS â†’ CATEGORY GROUPS")
    print("â”€" * 80)
    print("Testing: Abstract, domain-level terms should match GROUP categories")
    print_component_step(f"Executing {len(broad_tests)} broad term queries")
    print()
    
    broad_passed = 0
    broad_total = len(broad_tests)
    broad_results = []
    
    for term, expected_id, expected_name in broad_tests:
        matches = query_categories(term, top_k=3, min_confidence=similarity_distance_threshold)
        
        if matches and len(matches) > 0:
            top_match = matches[0]
            actual_id = top_match.get("id")
            actual_name = top_match.get("name")
            actual_type = top_match.get("type")
            distance = top_match.get("score")
            
            # Check: correct ID AND correct type (group)
            is_correct = (actual_id == expected_id and actual_type == "group")
            
            if is_correct:
                broad_passed += 1
            
            type_marker = f"[{actual_type.upper():10}]"
            print_result(
                is_correct,
                f"'{term:20}' â†’ {type_marker} {actual_name:30} ({actual_id})",
                f"Dist: {distance:.4f}"
            )
            
            broad_results.append({
                "term": term,
                "expected_id": expected_id,
                "expected_type": "group",
                "actual_id": actual_id,
                "actual_type": actual_type,
                "distance": distance,
                "passed": is_correct
            })
        else:
            print_result(False, f"'{term:20}' â†’ NO RESULTS", "")
            broad_results.append({
                "term": term,
                "expected_id": expected_id,
                "passed": False
            })
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PART B: SPECIFIC TERMS â†’ SUBCATEGORIES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    specific_tests = [
        ("dentist", "C304", "Dental"),
        ("coffee shop", "C806", "Cafes & Coffee Shops"),
        ("fuel", "C101", "Gas Station"),
        ("drugstore", "C302", "Pharmacy"),
        ("barber", "C701", "Hair Salon & Barber"),
        ("streaming", "C403", "Streaming Services"),
        ("veterinarian", "C1301", "Veterinary"),
        ("gym membership", "C1701", "Gym & Fitness Center"),
        ("lawyer fees", "C1801", "Legal Services"),
        ("car repair", "C1902", "Auto Repairs"),
    ]
    
    print("\n" + "â”€" * 80)
    print("PART B: SPECIFIC TERMS â†’ SUBCATEGORIES")
    print("â”€" * 80)
    print("Testing: Concrete, transaction-level terms should match SUBCATEGORY items")
    print_component_step(f"Executing {len(specific_tests)} specific term queries")
    print()
    
    specific_passed = 0
    specific_total = len(specific_tests)
    specific_results = []
    
    for term, expected_id, expected_name in specific_tests:
        matches = query_categories(term, top_k=3, min_confidence=similarity_distance_threshold)
        
        if matches and len(matches) > 0:
            top_match = matches[0]
            actual_id = top_match.get("id")
            actual_name = top_match.get("name")
            actual_type = top_match.get("type")
            distance = top_match.get("score")
            
            # Check: correct ID AND correct type (subcategory)
            is_correct = (actual_id == expected_id and actual_type == "subcategory")
            
            if is_correct:
                specific_passed += 1
            
            type_marker = f"[{actual_type.upper():10}]"
            print_result(
                is_correct,
                f"'{term:20}' â†’ {type_marker} {actual_name:30} ({actual_id})",
                f"Dist: {distance:.4f}"
            )
            
            specific_results.append({
                "term": term,
                "expected_id": expected_id,
                "expected_type": "subcategory",
                "actual_id": actual_id,
                "actual_type": actual_type,
                "distance": distance,
                "passed": is_correct
            })
        else:
            print_result(False, f"'{term:20}' â†’ NO RESULTS", "")
            specific_results.append({
                "term": term,
                "expected_id": expected_id,
                "passed": False
            })
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COMBINED SUMMARY AND EVALUATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    total_passed = broad_passed + specific_passed
    total_tests = broad_total + specific_total
    
    broad_accuracy = broad_passed / broad_total if broad_total > 0 else 0
    specific_accuracy = specific_passed / specific_total if specific_total > 0 else 0
    overall_accuracy = total_passed / total_tests if total_tests > 0 else 0
    
    print("\n" + "â•" * 80)
    print("ğŸ“Š COMBINED RESULTS")
    print("â•" * 80)
    print(f"Part A - Broad â†’ Groups:           {broad_passed:2}/{broad_total:2} ({broad_accuracy*100:5.1f}%)")
    print(f"Part B - Specific â†’ Subcategories:  {specific_passed:2}/{specific_total:2} ({specific_accuracy*100:5.1f}%)")
    print("â”€" * 80)
    print(f"Overall Semantic Accuracy:         {total_passed:2}/{total_tests:2} ({overall_accuracy*100:5.1f}%)")
    print("â•" * 80)
    
    # Evaluate against success criteria
    broad_pass = broad_accuracy >= 0.70
    specific_pass = specific_accuracy >= 0.90
    overall_pass = overall_accuracy >= 0.80
    
    print(f"\nâœ… SUCCESS CRITERIA EVALUATION:")
    print(f"   {'âœ…' if broad_pass else 'âŒ'} Broad â†’ Groups: â‰¥70%        (actual: {broad_accuracy*100:.1f}%)")
    print(f"   {'âœ…' if specific_pass else 'âŒ'} Specific â†’ Subcategories: â‰¥90% (actual: {specific_accuracy*100:.1f}%)")
    print(f"   {'âœ…' if overall_pass else 'âŒ'} Overall Accuracy: â‰¥80%        (actual: {overall_accuracy*100:.1f}%)")
    
    all_criteria_met = broad_pass and specific_pass and overall_pass
    
    print("\n" + "â”€" * 80)
    if all_criteria_met:
        print("ğŸ‰ ALL SUCCESS CRITERIA MET!")
        print("   Semantic understanding is working correctly.")
    else:
        print("âš ï¸  SOME CRITERIA NOT MET")
        if not broad_pass:
            print("   â†’ Broad terms not mapping well to groups (need better group descriptions)")
        if not specific_pass:
            print("   â†’ Specific terms not mapping well to subcategories (need better subcat descriptions)")
    print("â”€" * 80)
    
    print_test_summary(3, total_passed, total_tests)
    
    return {
        "test_name": "semantic_similarity_broad_vs_specific",
        "component": "Embedding Model + Rich Descriptions",
        "broad_results": {
            "passed": broad_passed,
            "total": broad_total,
            "accuracy": broad_accuracy,
            "queries": broad_results
        },
        "specific_results": {
            "passed": specific_passed,
            "total": specific_total,
            "accuracy": specific_accuracy,
            "queries": specific_results
        },
        "combined": {
            "total_passed": total_passed,
            "total_tests": total_tests,
            "overall_accuracy": overall_accuracy
        },
        "criteria_met": {
            "broad": broad_pass,
            "specific": specific_pass,
            "overall": overall_pass,
            "all_passed": all_criteria_met
        }
    }



# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUN SEMANTIC QUALITY TEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_semantic_quality_test() -> Dict[str, Any]:
    """
    Run Semantic Quality Test
    
    Executes Test 3 to validate semantic understanding quality.
    This is the critical test that validates whether rich conceptual
    descriptions enable proper broad vs specific disambiguation.
    
    Returns:
        dict: Test results with accuracy metrics
    """
    print("\n" + "=" * 80)
    print("ğŸ§  RAG SEMANTIC QUALITY TEST")
    print("=" * 80)
    print("Validating: Broadâ†’Groups, Specificâ†’Subcategories semantic mapping")
    print("=" * 80)
    
    # Run test
    results = test_semantic_similarity_broad_vs_specific()
    
    # Summary
    print("\n" + "=" * 80)
    print("ğŸ“Š SEMANTIC QUALITY TEST SUMMARY")
    print("=" * 80)
    
    broad_acc = results["broad_results"]["accuracy"]
    specific_acc = results["specific_results"]["accuracy"]
    overall_acc = results["combined"]["overall_accuracy"]
    
    print(f"Broad â†’ Groups:             {broad_acc*100:.1f}% (â‰¥70% required)")
    print(f"Specific â†’ Subcategories:   {specific_acc*100:.1f}% (â‰¥90% required)")
    print(f"Overall Accuracy:           {overall_acc*100:.1f}% (â‰¥80% required)")
    print("=" * 80)
    
    all_passed = results["criteria_met"]["all_passed"]
    
    if all_passed:
        print("\nâœ… SEMANTIC QUALITY TEST PASSED")
        print("   Rich descriptions enable proper semantic disambiguation!")
    else:
        print("\nâš ï¸  SEMANTIC QUALITY TEST NEEDS ATTENTION")
        print("   Some accuracy criteria not met. Check descriptions.")
    
    print("=" * 80)
    
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USAGE EXAMPLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
USAGE IN JUPYTER NOTEBOOK:

1. Run semantic quality test:
   from tests.test_rag_semantic_quality import run_semantic_quality_test
   results = run_semantic_quality_test()

2. Run test directly:
   from tests.test_rag_semantic_quality import test_semantic_similarity_broad_vs_specific
   test_semantic_similarity_broad_vs_specific()

3. Check specific results:
   results = run_semantic_quality_test()
   print(f"Broad accuracy: {results['broad_results']['accuracy']*100:.1f}%")
   print(f"Specific accuracy: {results['specific_results']['accuracy']*100:.1f}%")
   
4. Analyze failures:
   for query in results['broad_results']['queries']:
       if not query['passed']:
           print(f"Failed: {query['term']} â†’ got {query.get('actual_id')} instead of {query['expected_id']}")
"""